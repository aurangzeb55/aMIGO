# AI Virtual Companion

![AI Virtual Companion](https://img.shields.io/badge/AI-Virtual%20Companion-blue?style=for-the-badge&logo=ai)
![Node.js](https://img.shields.io/badge/Node.js-v16+-green?style=for-the-badge&logo=node.js)
![npm](https://img.shields.io/badge/npm-v7+-red?style=for-the-badge&logo=npm)
![License](https://img.shields.io/badge/License-MIT-yellow?style=for-the-badge)

### üåü **Welcome to AI Virtual Companion!**
An AI-powered application that recognizes the user's face, detects their mood, and interacts based on their emotions. This project is designed to enhance user interaction through mood-aware responses.

---

## üöÄ Features

- **Facial Recognition**: Identifies the user's face securely.
- **Mood Detection**: Detects the user‚Äôs mood (happy, sad, neutral, etc.).
- **Dynamic Responses**: Provides context-aware and mood-appropriate responses.
- **Real-Time Interaction**: Fast and responsive AI conversation.

---

## üõ†Ô∏è Requirements

Make sure the following are installed before running the application:

- **Ollama** (for AI integration)
- **Llama 3.2** (for model compatibility)
- **Node.js** (v16 or higher)

---

## üì• Installation

1. Clone the repository:

   ```bash
   git clone https://github.com/your-username/ai-virtual-companion.git
   cd ai-virtual-companion
   ```

2. Install dependencies:

   ```bash
   npm install
   ```

3. Ensure **Ollama** and **Llama 3.2** are installed on your system.

   - [Install Ollama](https://ollama.com/install-guide)
   - [Install Llama 3.2](https://llama.ai/documentation)

---

## üíª Usage

1. Start the development server:

   ```bash
   npm run dev
   ```

2. Open your browser and navigate to:

   ```
   http://localhost:5173
   ```

3. Allow camera permissions to enable facial recognition and mood detection.

---

## üé• Demo

![Demo Animation](https://user-images.githubusercontent.com/your-username/demo.gif)

---

## ü§ñ How It Works

1. **Face Recognition**: Uses a pre-trained model to recognize the user's face.
2. **Mood Detection**: Analyzes facial expressions to detect mood.
3. **Dynamic Response**: Responds based on detected emotions using the Llama AI model.

---

## ü§ù Contributing

Contributions are welcome! Feel free to:

- Fork this repository
- Create a new branch
- Submit a pull request

---

## üåê Connect With Me

[![GitHub](https://img.shields.io/badge/GitHub-YourUsername-black?style=for-the-badge&logo=github)](https://github.com/saaadshk)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-YourName-blue?style=for-the-badge&logo=linkedin)](https://www.linkedin.com/in/saad-shaikh-b23089214)

---

Made with ‚ù§Ô∏è by **Your Name**
